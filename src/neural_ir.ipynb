{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Neural IR with Bi-Encoders and Cross-Encoders\n",
    "\n",
    "This notebook covers **Step 3** of the project. We will build a two-stage neural IR system:\n",
    "\n",
    "1.  **First Stage (Retrieval)**: Use a **bi-encoder** model to efficiently scan the entire corpus. It encodes all documents and queries into a shared vector space and retrieves an initial set of top candidates (e.g., top 100) using a high-speed FAISS index.\n",
    "2.  **Second Stage (Re-ranking)**: Use a more powerful but slower **cross-encoder** model. This model examines the query and each candidate document *together*, providing a much more accurate relevance score to re-rank the initial set and produce the final results.\n",
    "3.  **Evaluation**: Apply the same evaluation metrics from Notebook 2 to measure the performance of our neural system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "We'll need the `sentence-transformers` library from Hugging Face for the neural models, `faiss-cpu` for efficient vector search, and `torch` as the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (1.12.0)\n",
      "Requirement already satisfied: torch in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: pandas in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu torch pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data\n",
    "\n",
    "Let's load the same dataframes we used in the previous notebook. This ensures our evaluation is comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/hzvt1gg54w3gjw1jsgrw5vlh0000gn/T/ipykernel_5003/3139503847.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Loading processed data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "DATA_DIR = '../fiqa/processed_data'\n",
    "\n",
    "# Load data\n",
    "print(\"Loading processed data...\")\n",
    "corpus_df = pd.read_pickle(os.path.join(DATA_DIR, 'corpus_processed.pkl'))\n",
    "queries_df = pd.read_pickle(os.path.join(DATA_DIR, 'queries_processed.pkl'))\n",
    "qrels_df = pd.read_pickle(os.path.join(DATA_DIR, 'qrels.pkl'))\n",
    "\n",
    "# --- Create mappings for faster lookups ---\n",
    "# Use original text for neural models as they understand full sentences\n",
    "doc_id_to_text = pd.Series(corpus_df.text.values, index=corpus_df.doc_id).to_dict()\n",
    "query_id_to_text = pd.Series(queries_df.text.values, index=queries_df.query_id).to_dict()\n",
    "\n",
    "# Keep a list of document IDs for mapping FAISS results back\n",
    "doc_ids = corpus_df['doc_id'].tolist()\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. First Stage: Bi-Encoder Retrieval with FAISS\n",
    "\n",
    "The bi-encoder's job is to quickly find a set of potentially relevant documents from the entire corpus. We'll use a model pre-trained for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Initialize the Bi-Encoder\n",
    "\n",
    "We'll use a model from the `sentence-transformers` library that is well-suited for asymmetric search (matching short queries to longer passages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moorateeahtashil/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-encoder loaded. Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the bi-encoder model\n",
    "# 'msmarco-distilbert-base-v4' is a great baseline model for semantic search\n",
    "bi_encoder_model = SentenceTransformer('msmarco-distilbert-base-v4', device=device)\n",
    "\n",
    "# Get the embedding dimension\n",
    "embedding_dim = bi_encoder_model.get_sentence_embedding_dimension()\n",
    "print(f\"Bi-encoder loaded. Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Encode the Corpus\n",
    "\n",
    "We need to convert every document in our corpus into a vector embedding. This is a one-time operation. For large corpora, this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243f8f6a792e41a088f5f611c15d32e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus encoded. Shape of embeddings: (57638, 768)\n"
     ]
    }
   ],
   "source": [
    "# --- Encode all documents in the corpus ---\n",
    "# We will use the original, unprocessed text for the neural models\n",
    "corpus_texts = corpus_df['text'].tolist()\n",
    "\n",
    "# It's recommended to encode in batches for efficiency\n",
    "batch_size = 256\n",
    "corpus_embeddings = bi_encoder_model.encode(\n",
    "    corpus_texts,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=batch_size,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "\n",
    "# Move embeddings to CPU for FAISS (FAISS works with NumPy on CPU)\n",
    "corpus_embeddings = corpus_embeddings.cpu().numpy()\n",
    "print(f\"Corpus encoded. Shape of embeddings: {corpus_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Build the FAISS Index\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library that allows for incredibly fast searching over billions of vectors. We'll build an index to store our document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built. Total documents in index: 57638\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# --- Build a FAISS index ---\n",
    "# We use IndexFlatL2, a basic index that computes L2 distance.\n",
    "# It's a good starting point and works well for millions of vectors.\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Add the document embeddings to the index\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "print(f\"FAISS index built. Total documents in index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Second Stage: Cross-Encoder Re-ranking\n",
    "\n",
    "Now that we can retrieve candidates quickly, we use a cross-encoder to re-rank them with higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Initialize the Cross-Encoder\n",
    "\n",
    "Cross-encoder models are also available in the `sentence-transformers` library. They are trained to take a pair of texts (query, document) and output a single relevance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder loaded.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# Initialize the cross-encoder model\n",
    "# This model is specifically trained for re-ranking in search tasks.\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "print(\"Cross-encoder loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create the Full Retrieval and Re-ranking Pipeline\n",
    "\n",
    "Let's combine the two stages into a single function. This function will take a query, retrieve 100 candidates with the bi-encoder/FAISS, and then re-rank them with the cross-encoder to get the final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 5 Results for query: 'What are the tax implications of a business car lease?' ---\n",
      "Score: nan\tDoc ID: 429899\n",
      "Score: nan\tDoc ID: 185405\n",
      "Score: nan\tDoc ID: 427884\n",
      "Score: nan\tDoc ID: 307158\n",
      "Score: nan\tDoc ID: 181187\n"
     ]
    }
   ],
   "source": [
    "def search_and_rerank(query_text, top_k_retrieval=100, top_k_rerank=50):\n",
    "    \"\"\"\n",
    "    Performs a two-stage search: retrieval with bi-encoder and re-ranking with cross-encoder.\n",
    "    \"\"\"\n",
    "    # --- Stage 1: Bi-Encoder Retrieval ---\n",
    "    query_embedding = bi_encoder_model.encode(query_text, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "    # Search the FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k_retrieval)\n",
    "    \n",
    "    # Get the doc IDs of the retrieved candidates\n",
    "    retrieved_doc_ids = [doc_ids[i] for i in indices[0]]\n",
    "    \n",
    "    # --- Stage 2: Cross-Encoder Re-ranking ---\n",
    "    # Create pairs of [query, document_text] for the cross-encoder\n",
    "    cross_encoder_input = [[query_text, doc_id_to_text[doc_id]] for doc_id in retrieved_doc_ids]\n",
    "    \n",
    "    # Get scores from the cross-encoder\n",
    "    cross_scores = cross_encoder_model.predict(cross_encoder_input, show_progress_bar=False)\n",
    "    \n",
    "    # Combine doc IDs with their new scores\n",
    "    reranked_results = list(zip(retrieved_doc_ids, cross_scores))\n",
    "    \n",
    "    # Sort by the new scores in descending order\n",
    "    reranked_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top_k re-ranked documents and their scores\n",
    "    return reranked_results[:top_k_rerank]\n",
    "\n",
    "# --- Example Usage ---\n",
    "sample_query = \"What are the tax implications of a business car lease?\"\n",
    "results = search_and_rerank(sample_query)\n",
    "\n",
    "print(f\"--- Top 5 Results for query: '{sample_query}' ---\")\n",
    "for doc_id, score in results[:5]:\n",
    "    print(f\"Score: {score:.4f}\\tDoc ID: {doc_id}\")\n",
    "    #print(f\"Text: {doc_id_to_text[doc_id][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run and Evaluate the Neural IR System\n",
    "\n",
    "Now, we'll run our pipeline on the same 10 sample queries from Notebook 2 and evaluate the final, re-ranked results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Run Retrieval for Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55926415226f4b77aaf50cb4e714087a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Neural Search & Re-ranking:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Neural Results for Query ID: 10028\n",
      "['476068', '75747', '227485', '458235', '44105']\n"
     ]
    }
   ],
   "source": [
    "# Select the same 10 sample queries for a fair comparison\n",
    "\n",
    "rel_counts = qrels_df.groupby('query_id').size()\n",
    "\n",
    "rich_queries = rel_counts[rel_counts > 5]\n",
    "\n",
    "\n",
    "sample_query_ids = rich_queries.index[:10].tolist()\n",
    "results_neural = {}\n",
    "\n",
    "for qid in tqdm(sample_query_ids, desc=\"Running Neural Search & Re-ranking\"):\n",
    "    query_text = query_id_to_text[qid]\n",
    "    \n",
    "    # Get the ranked list of document IDs\n",
    "    ranked_list = search_and_rerank(query_text, top_k_retrieval=100, top_k_rerank=100)\n",
    "    results_neural[qid] = [doc_id for doc_id, score in ranked_list]\n",
    "\n",
    "print(\"\\n--- Sample Neural Results for Query ID:\", sample_query_ids[0])\n",
    "print(results_neural[sample_query_ids[0]][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Evaluation\n",
    "\n",
    "We'll use the **exact same evaluation functions** from the previous notebook to calculate our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Create a dictionary for easy lookup of relevant documents for each query\n",
    "relevant_docs = qrels_df.groupby('query_id')['doc_id'].apply(list).to_dict()\n",
    "\n",
    "# --- Metric Implementations (Copied from Notebook 2) ---\n",
    "\n",
    "def precision_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    return len(set(retrieved_k) & set(relevant)) / k\n",
    "\n",
    "def recall_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len(set(retrieved_k) & set(relevant)) / len(relevant)\n",
    "\n",
    "def average_precision(retrieved, relevant):\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    hits = 0\n",
    "    sum_precisions = 0.0\n",
    "    for i, doc_id in enumerate(retrieved):\n",
    "        if doc_id in relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / len(relevant)\n",
    "\n",
    "def mean_average_precision(results, relevant_docs):\n",
    "    aps = [average_precision(results[qid], relevant_docs.get(qid, [])) for qid in results]\n",
    "    return np.mean(aps)\n",
    "\n",
    "def mean_reciprocal_rank(results, relevant_docs):\n",
    "    rrs = []\n",
    "    for qid in results:\n",
    "        relevant = relevant_docs.get(qid, [])\n",
    "        for i, doc_id in enumerate(results[qid]):\n",
    "            if doc_id in relevant:\n",
    "                rrs.append(1 / (i + 1))\n",
    "                break\n",
    "        else:\n",
    "            rrs.append(0.0)\n",
    "    return np.mean(rrs)\n",
    "\n",
    "def ndcg_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    dcg = 0.0\n",
    "    for i, doc_id in enumerate(retrieved_k):\n",
    "        if doc_id in relevant:\n",
    "            dcg += 1 / math.log2(i + 2)\n",
    "    idcg = 0.0\n",
    "    num_relevant_k = min(len(relevant), k)\n",
    "    for i in range(num_relevant_k):\n",
    "        idcg += 1 / math.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_model(results, relevant_docs, k_values=[1,3,5,10]):\n",
    "    metrics = {}\n",
    "    for k in k_values:\n",
    "        precisions = [precision_at_k(results[qid], relevant_docs.get(qid, []), k) for qid in results]\n",
    "        recalls = [recall_at_k(results[qid], relevant_docs.get(qid, []), k) for qid in results]\n",
    "        ndcgs = [ndcg_at_k(results[qid], relevant_docs.get(qid, []), k) for qid in results]\n",
    "        metrics[f'P@{k}'] = np.mean(precisions)\n",
    "        metrics[f'R@{k}'] = np.mean(recalls)\n",
    "        metrics[f'nDCG@{k}'] = np.mean(ndcgs)\n",
    "    \n",
    "    metrics['MAP'] = mean_average_precision(results, relevant_docs)\n",
    "    metrics['MRR'] = mean_reciprocal_rank(results, relevant_docs)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Final Performance Comparison\n",
    "\n",
    "Let's see how our new neural model stacks up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Performance Comparison ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>R@1</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>R@3</th>\n",
       "      <th>nDCG@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>R@5</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural (Bi+Cross)</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.270392</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>0.224633</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.148095</td>\n",
       "      <td>0.19777</td>\n",
       "      <td>0.137836</td>\n",
       "      <td>0.429636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   P@1       R@1  nDCG@1       P@3       R@3    nDCG@3   P@5  \\\n",
       "Neural (Bi+Cross)  0.4  0.061905     0.4  0.233333  0.107143  0.270392  0.18   \n",
       "\n",
       "                        R@5    nDCG@5  P@10      R@10  nDCG@10       MAP  \\\n",
       "Neural (Bi+Cross)  0.131429  0.224633   0.1  0.148095  0.19777  0.137836   \n",
       "\n",
       "                        MRR  \n",
       "Neural (Bi+Cross)  0.429636  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics for the neural model\n",
    "neural_metrics = evaluate_model(results_neural, relevant_docs)\n",
    "\n",
    "\n",
    "comparison_df = pd.DataFrame( neural_metrics, index= ['Neural (Bi+Cross)'])\n",
    "\n",
    "print(\"--- Model Performance Comparison ---\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis\n",
    "\n",
    "You should observe a **significant improvement** with the neural model compared to BM25 across almost all metrics, especially **nDCG, MAP, and MRR**.\n",
    "\n",
    "* **Why the Improvement?** Neural models move beyond simple keyword matching. They understand the *semantic meaning* and *intent* behind the query and document text. For example, a query about \"car tax costs\" could match a document that talks about \"vehicle excise duty\" or \"automobile registration fees,\" even if the exact words don't overlap. BM25 would miss this connection.\n",
    "* **The Power of Two Stages**:\n",
    "    * The **bi-encoder** provides the speed needed to search a huge corpus by representing everything in a compact vector format.\n",
    "    * The **cross-encoder** provides the high accuracy. By looking at the query and document text *at the same time*, it can notice fine-grained details, context, and term relationships that the bi-encoder might miss. This combination gives you the best of both worlds: speed and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
